{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77042693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Cyclist_env_RDA import cyclist_env\n",
    "from time import time\n",
    "from scipy.linalg import dft\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from numpy.fft import fft, ifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac10d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFAR検出器の実装\n",
    "\n",
    "def ca_cfar_2d(x_db, n_train=(1,7), n_guard=(1,5), pfa=1e-6, convert_from_db=False):\n",
    "    \"\"\"\n",
    "    x_db: (B,1,H,W) input map (dB or linear)\n",
    "    n_train: (th, tw) training half window size\n",
    "    n_guard: (gh, gw) guard half window size\n",
    "    \"\"\"\n",
    "    if convert_from_db:\n",
    "        x = 10 ** (x_db / 10.0)  # dB -> linear\n",
    "    else:\n",
    "        x = x_db\n",
    "\n",
    "    B, C, H, W = x.shape\n",
    "    th, tw = n_train\n",
    "    gh, gw = n_guard\n",
    "\n",
    "    # Total kernel size\n",
    "    kh = 2 * (th + gh) + 1\n",
    "    kw = 2 * (tw + gw) + 1\n",
    "\n",
    "    # Make training mask\n",
    "    kernel = torch.ones((1,1,kh,kw), device=x.device)\n",
    "    kernel[:, :, th-gh:th+gh+1, tw-gw:tw+gw+1] = 0  # guard + CUT = 0\n",
    "\n",
    "    N_train = kernel.sum().item()\n",
    "    alpha = N_train * (pfa ** (-1.0 / N_train) - 1.0)\n",
    "\n",
    "    # Convolution = training sum\n",
    "    x_pad = F.pad(x, (kw//2, kw//2, kh//2, kh//2), mode=\"reflect\")\n",
    "    train_sum = F.conv2d(x_pad.double(), kernel.double())\n",
    "    noise_est = train_sum / N_train\n",
    "\n",
    "    threshold = alpha * noise_est\n",
    "    detections = x > threshold\n",
    "    return detections, threshold, noise_est\n",
    "\n",
    "# 変更前: tar_thres = -25\n",
    "# 変更後: tar_thres = -35  (または -30)\n",
    "def thresholder(radar, idx_est, tar_thres = -25, cyvethres = 2.638):\n",
    "    cy_idx, ve_idx = [], []\n",
    "    radar = 20*torch.log10(radar)\n",
    "    for i in range(len(idx_est)):\n",
    "        rangeofinterest = radar[:5, max(0, idx_est[i]-5):min(idx_est[i]+5, 589)].flatten()\n",
    "        top2 = rangeofinterest.topk(2).values.mean()\n",
    "        if top2 > tar_thres:\n",
    "            cy_idx.append(idx_est[i])\n",
    "            ve_idx.append(idx_est[i]) \n",
    "\n",
    "    cy_idx_cleans = cleansing(cy_idx)\n",
    "    ve_idx_cleans = cleansing(ve_idx)\n",
    "\n",
    "    return cy_idx_cleans, ve_idx_cleans\n",
    "    \n",
    "def cleansing(idx, tol = 5):\n",
    "    if idx :\n",
    "        res = [idx[0]]\n",
    "        for i in range(1,len(idx)):\n",
    "            if idx[i]<=idx[i-1]+5:\n",
    "                continue\n",
    "            res.append(idx[i])\n",
    "        return res\n",
    "    else: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02bd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stevec(N_ant, angle):\n",
    "    resp = (np.arange(N_ant)-N_ant*0.5+0.5).reshape([-1,1])\n",
    "    resp = np.exp(1j*resp*np.pi*np.sin(angle))\n",
    "    return np.matrix(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "084e05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_method(Y, N_ant):\n",
    "    Y_music = np.mean(Y, axis=0)\n",
    "    R_yy = Y_music@np.conjugate(np.transpose(Y_music))\n",
    "    # print(np.linalg.eig(R_yy)[0])\n",
    "    U = np.linalg.eig(R_yy)[1][:,5:]\n",
    "\n",
    "    resp = []\n",
    "    argm = (np.arange(1800)-900)/100\n",
    "    for val in argm:\n",
    "        stv = stevec(N_ant, val*np.pi/180)\n",
    "        p = stv.T@U\n",
    "        pp = p*np.conjugate(np.transpose(p))\n",
    "        resp.append(1/(np.abs(pp)**2).A1)\n",
    "\n",
    "    M = max(resp)\n",
    "    est_ang = []\n",
    "    \n",
    "    a, b = resp[0][0], resp[1][0]\n",
    "    for i in range(1,len(argm)-1):\n",
    "        c = resp[i+1][0]\n",
    "        if a < b and b > c and b > 0.2 * M:\n",
    "            est_ang.append(argm[i])\n",
    "        a, b = b, c\n",
    "    return est_ang\n",
    "\n",
    "#angle_list = MUSIC_method(Y)\n",
    "#print(\"Estimated angles:\", angle_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3c75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_method_Debug(eig_val, N_ant, num_signals, resp, argm, M):\n",
    "    \"\"\"\n",
    "    MUSIC法の状態を診断するためのデバッグ関数\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"【MUSIC法 デバッグ情報】\")\n",
    "    \n",
    "    # --- 1. 数値情報の出力 ---\n",
    "    # 固有値の絶対値（大きい順）\n",
    "    eig_abs = np.abs(eig_val)\n",
    "    print(f\"1. 固有値 (大きい順):\\n{eig_abs}\")\n",
    "    \n",
    "    # 推定された信号数と閾値情報\n",
    "    print(f\"2. 設定信号数 (K): {num_signals}\")\n",
    "    print(f\"3. スペクトル最大値 (M): {M:.2e}\")\n",
    "    print(f\"4. 現在の閾値 (20%): {0.2 * M:.2e}\")\n",
    "\n",
    "    # --- 2. グラフ描画 (重要) ---\n",
    "    try:\n",
    "        \"\"\"\n",
    "        # プロットエリアを2つ作成 (左: 固有値分布, 右: MUSICスペクトル)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        \n",
    "        # === 左のグラフ: 固有値分布 (Scree Plot) ===\n",
    "        # これを見ることで、信号がノイズから分離できているか確認できます\n",
    "        ax1.plot(range(1, len(eig_abs) + 1), eig_abs, 'bo-', markersize=8)\n",
    "        ax1.set_title('Eigenvalue Distribution (Scree Plot)')\n",
    "        ax1.set_xlabel('Index')\n",
    "        ax1.set_ylabel('Eigenvalue (log scale)')\n",
    "        ax1.set_yscale('log') # 固有値は桁が違うことが多いので対数がおすすめ\n",
    "        ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "        \n",
    "        # 信号部分とノイズ部分の境界に線を引く\n",
    "        ax1.axvline(x=num_signals + 0.5, color='r', linestyle='--', label=f'Separation (K={num_signals})')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # === 右のグラフ: MUSICスペクトル ===\n",
    "        # どこにピークがあり、閾値でどう切られているか確認します\n",
    "        resp_array = np.array(resp).flatten() # 形状を1次元に統一\n",
    "        \n",
    "        ax2.plot(argm, resp_array, label='MUSIC Spectrum')\n",
    "        ax2.set_title(f'MUSIC Spectrum (N_ant={N_ant}, K={num_signals})')\n",
    "        ax2.set_xlabel('Angle [deg]')\n",
    "        ax2.set_ylabel('Spectrum Power')\n",
    "        ax2.set_yscale('log') # スペクトルも対数で見ると弱いピークが見つけやすい\n",
    "        ax2.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "        \n",
    "        # 閾値の線を引く (赤の点線)\n",
    "        threshold_val = 0.2 * M\n",
    "        ax2.axhline(y=threshold_val, color='r', linestyle='--', label='Threshold (20%)')\n",
    "        \n",
    "        # もし閾値を5%に下げたらどう見えるかも参考として表示 (緑の点線)\n",
    "        ax2.axhline(y=0.05 * M, color='g', linestyle=':', label='Threshold (5%)')\n",
    "        \n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"-> 診断用グラフを描画しました\")\n",
    "        \"\"\"\n",
    "        \n",
    "        # --- ピークのグラフだけ表示 ---\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        resp_array = np.array(resp).flatten() # 形状を1次元に統一\n",
    "        \n",
    "        ax.plot(argm, resp_array, label='MUSIC Spectrum')\n",
    "        ax.set_title(f'MUSIC Spectrum (N_ant={N_ant}, K={num_signals})')\n",
    "        ax.set_xlabel('Angle [deg]')\n",
    "        ax.set_ylabel('Spectrum Power')\n",
    "        ax.set_yscale('log') # スペクトルも対数で見ると弱いピークが見つけやすい\n",
    "        ax.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "        \n",
    "        # 閾値の線を引く (赤の点線)\n",
    "        threshold_val = 0.2 * M\n",
    "        ax.axhline(y=threshold_val, color='r', linestyle='--', label='Threshold (20%)')\n",
    "        \n",
    "        # もし閾値を5%に下げたらどう見えるかも参考として表示 (緑の点線)\n",
    "        ax.axhline(y=0.05 * M, color='g', linestyle=':', label='Threshold (5%)')\n",
    "        \n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"-> 診断用グラフを描画しました\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"-> グラフ描画中にエラーが発生しました: {e}\")\n",
    "        \n",
    "    print(\"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea60054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_method_improved(Y, N_ant, num_signals):\n",
    "    Y_music = np.mean(Y, axis=0)\n",
    "    R_yy = Y_music@np.conjugate(np.transpose(Y_music))\n",
    "    # 1.固有値分解\n",
    "    eig_val, eig_vec = np.linalg.eig(R_yy)\n",
    "\n",
    "    # 2.固有値をソートして雑音部分空間を取得\n",
    "    idx = np.abs(eig_val).argsort()[::-1]\n",
    "    # インデックスによって固有値と固有ベクトルの対応関係を維持しつつソート\n",
    "    eig_val = eig_val[idx]\n",
    "    eig_vec = eig_vec[:, idx]\n",
    "    # 雑音部分空間Uを取得\n",
    "\n",
    "    # num_signalsを固有値から推定?\n",
    "    \n",
    "    # デバッグ用\n",
    "    num_signals = 5\n",
    "    \n",
    "    U = eig_vec[:, num_signals:]\n",
    "\n",
    "    # 3.雑音部分空間とvalごとのステアリングベクトルの内積を計算\n",
    "    resp = []\n",
    "    argm = (np.arange(1800)-900)/100\n",
    "    for val in argm:\n",
    "        # ステアリングベクトルの計算\n",
    "        stv = stevec(N_ant, val*np.pi/180)\n",
    "        # 雑音部分空間との内積\n",
    "        p = stv.T@U\n",
    "        # L2ノルムの二乗を計算(pp^H)\n",
    "        pp = p*np.conjugate(np.transpose(p))\n",
    "        # A1は行列を1次元配列に変換するメソッド\n",
    "        # respに逆数を追加\n",
    "        # 分子は角度推定の上では不要なので省略している\n",
    "        resp.append(1/(np.abs(pp)**2).A1)\n",
    "\n",
    "    # 4.ピーク検出\n",
    "    M = np.max(resp)\n",
    "    \n",
    "    # デバッグ用\n",
    "    #MUSIC_method_Debug(eig_val, N_ant, num_signals, resp, argm, M)\n",
    "    \n",
    "    est_ang = []\n",
    "    # 三点比較によるピーク検出\n",
    "    a, b = resp[0][0], resp[1][0]\n",
    "    for i in range(1,len(argm)-1):\n",
    "        c = resp[i+1][0]\n",
    "        if a < b and b > c and b > 0.2 * M:\n",
    "        #if a < b and b > c and b > 0.05 * M:\n",
    "            est_ang.append(argm[i])\n",
    "        a, b = b, c\n",
    "    return est_ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3681e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_xy(range_idx, angle_deg):\n",
    "    \"\"\"\n",
    "    range_idx: cy_idxs_pred の値 (例: 496)\n",
    "    angle_deg: MUSIC法で推定した角度 [度] (例: est_ang[0])\n",
    "    \"\"\"\n",
    "    p_bs = np.array([250, -18, 50])\n",
    "\n",
    "    offset = 3411\n",
    "    # (1) 距離の計算 [m]\n",
    "    # サンプル番号 = インデックス + オフセット\n",
    "    sample_idx = range_idx + offset\n",
    "    # 往復時間 = サンプル番号 * Tc\n",
    "    # 距離 = 往復時間 * c / 2\n",
    "    R = (sample_idx * Tc * env.c) / 2\n",
    "\n",
    "    # 三次元距離を二次元距離に変換\n",
    "    height_diff = p_bs[2] - 1\n",
    "    if R > height_diff:\n",
    "        R_horizontal = np.sqrt(R**2 - height_diff**2)\n",
    "    else:\n",
    "        R_horizontal = 0\n",
    "\n",
    "    # (2) 角度の計算 [rad]\n",
    "    # 推定角度をラジアンに変換し、基準角度(refangle)を足す\n",
    "    # anglecalの逆演算: cy_ang = arctan(...) - refangle なので\n",
    "    # arctan(...) = cy_ang + refangle\n",
    "    theta_world = np.deg2rad(angle_deg) + refangle\n",
    "\n",
    "    # (3) XY座標の計算 [m]\n",
    "    # 基地局(p_bs)からの相対位置\n",
    "    # cy_denum (dx) = R * cos(theta)\n",
    "    # cy_nu (dy) = R * sin(theta)\n",
    "    dx = R_horizontal * np.cos(theta_world)\n",
    "    dy = R_horizontal * np.sin(theta_world)\n",
    "\n",
    "    # 世界座標（絶対座標）に変換\n",
    "    # cy_denum = bs[0] - cy[0]  =>  cy[0] = bs[0] - dx\n",
    "    # cy_nu    = cy[1] - bs[1]  =>  cy[1] = bs[1] + dy\n",
    "    x = p_bs[0] - dx\n",
    "    y = p_bs[1] + dy\n",
    "\n",
    "    return x, y, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9fb3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFT (N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang):\n",
    "    # DFTの処理\n",
    "    Dopp_dft = dft(N_trans)/np.sqrt(N_trans)\n",
    "    Y_dft = np.zeros((N_trans, N_ant, rx_sample), dtype=np.complex128)\n",
    "    for i in range(N_ant):\n",
    "        Y_dft[:,i,:] = Dopp_dft@Y[:,i,:]\n",
    "    val, res, rdresp = 0, [], np.zeros((N_trans,590), dtype=np.complex128)\n",
    "    Q = 1\n",
    "\n",
    "    # 結果を保存するリスト\n",
    "    detected_objects = []\n",
    "    \n",
    "    # レンジドップラーマップ用のリスト\n",
    "    rd_maps = []\n",
    "    \n",
    "    P_range = np.arange(590)+3411\n",
    "    #P_range = np.arange(150) + 3800\n",
    "    \n",
    "    for i in range(len(est_ang)):\n",
    "        current_angle = est_ang[i]\n",
    "        #  他の角度の結果と混ざらないように rdresp_single を使う\n",
    "        rdresp_single = np.zeros((N_trans, 590), dtype=np.complex128)\n",
    "        ang_rad = current_angle * np.pi / 180\n",
    "        dup = np.ones((N_trans, 1, 1), dtype=np.complex128)\n",
    "        \n",
    "        # マッチドフィルタの処理\n",
    "        for p in P_range: # レンジ方向のループ\n",
    "            # pが距離を表す\n",
    "            # pをもとにSN比を最大化するインパルス応答を作成\n",
    "            X_cand = np.zeros((N_ant, rx_sample), dtype=np.complex128)\n",
    "            last = min(p+N_sample, rx_sample)\n",
    "            X_cand[:,p:last] += tx[:,:last-p]\n",
    "\n",
    "            g = np.conjugate(stevec(N_ant, ang_rad))@np.conjugate(np.transpose(stevec(N_ant, ang_rad)))@X_cand\n",
    "            g_mat = dup*np.array(g)\n",
    "            metric = np.sum(np.multiply(np.conjugate(Y_dft), g_mat), axis=(1,2))\n",
    "            \n",
    "            # ここで rdresp ではなく rdresp_single に保存\n",
    "            rdresp_single[:, p-3411] = metric\n",
    "            \n",
    "        # 【追加】完成したマップをリストに保存 (コピーして保存)\n",
    "        rd_maps.append(rdresp_single.copy())\n",
    "        rd_maps.append(i)\n",
    "            \n",
    "        # CFAR検出器の利用\n",
    "        radar_in = torch.tensor(abs(rdresp_single)).unsqueeze(0).unsqueeze(0)\n",
    "        detections, _, _ = ca_cfar_2d(radar_in, convert_from_db=False)\n",
    "        idx_est = torch.nonzero(detections[0,0,0], as_tuple=True)[0].tolist()\n",
    "        current_range_idxs, _ = thresholder(radar_in[0,0], idx_est)\n",
    "        \n",
    "        print(\"検出した距離：\", current_range_idxs)\n",
    "        print(\"検出した速度\")\n",
    "        \n",
    "        # 座標変換と結果保存\n",
    "        if len(current_range_idxs) > 0:\n",
    "            print(f\"角度 {current_angle:.2f} 度 のマップからの検出:\")\n",
    "            for r_idx in current_range_idxs:\n",
    "                x_est, y_est, r_est = idx_to_xy(r_idx, current_angle)\n",
    "                detected_objects.append([r_est, current_angle ,x_est, y_est])\n",
    "                print(f\"  -> Index: {r_idx}, Range: {r_est:.2f}m, X: {x_est:.2f}m, Y: {y_est:.2f}m\")\n",
    "        else:\n",
    "            print(f\"ターゲット不検出\")\n",
    "    return detected_objects, rd_maps\n",
    "\n",
    "#Y, phys_quantities = get_snapshot_data(100,0)\n",
    "#est_ang = MUSIC_method(Y)\n",
    "#detected_objects = DFT(N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang)\n",
    "#print(\"Detected objects (X, Y):\", detected_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b858f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT(N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang):\n",
    "    # ドップラー処理\n",
    "    Dopp_dft = dft(N_trans)/np.sqrt(N_trans)\n",
    "    Y_dft = np.zeros((N_trans, N_ant, rx_sample), dtype=np.complex128)\n",
    "    for i in range(N_ant):\n",
    "        Y_dft[:,i,:] = Dopp_dft@Y[:,i,:]\n",
    "\n",
    "    detected_objects = []\n",
    "    rd_maps = []\n",
    "\n",
    "    P_range = np.arange(590)+3411\n",
    "\n",
    "    # FFTによる位置推定処理\n",
    "    tx_arr = np.asarray(tx) # Shape:(N_ant, N_sample)\n",
    "    n_fft = 2**(int(rx_sample + N_sample).bit_length())\n",
    "    TX_F_all = fft(tx_arr, n=n_fft, axis=1) # 送信信号の全チャネルFFT\n",
    "    Y_F_all = fft(Y_dft, n=n_fft, axis=2) # 受信信号の全チャネルFFT\n",
    "\n",
    "    for i in range(len(est_ang)):\n",
    "        current_angle = est_ang[i]\n",
    "        ang_rad = current_angle * np.pi / 180\n",
    "        \n",
    "        # ステアリングベクトル (N_ant, 1)\n",
    "        s_vec = np.asarray(stevec(N_ant, ang_rad))\n",
    "\n",
    "        \n",
    "        # --- 周波数領域でのビームフォーミング ---\n",
    "        \n",
    "        # 受信信号の合成: Y_combined = sum(Y * s)\n",
    "        # s_vec を (1, N_ant, 1) に変形して放送\n",
    "        # Y_F_all: (N_trans, N_ant, n_fft)\n",
    "        # 重み付け和をとってアンテナ次元を潰す -> (N_trans, n_fft)\n",
    "        w_vec = np.conjugate(s_vec).reshape(1, N_ant, 1)\n",
    "        Y_F_combined = np.sum(Y_F_all * w_vec, axis=1)\n",
    "        \n",
    "        # 送信信号(レプリカ)の合成: X_combined = sum(X * s*)\n",
    "        # 元の数式 g = s* s^H X より、Xにかかる重みは s^H (つまり sの共役)\n",
    "        # TX_F_all: (N_ant, n_fft)\n",
    "        s_vec_conj_reshape = np.conjugate(s_vec).reshape(N_ant, 1)\n",
    "        TX_F_combined = np.sum(TX_F_all * s_vec_conj_reshape, axis=0) # -> (n_fft,)\n",
    "        \n",
    "        # --- 相関演算 (Correlation) ---\n",
    "        # Correlation = IFFT( FFT(Y) * conj(FFT(X)) )\n",
    "        # Broadcasting: (N_trans, n_fft) * (n_fft,)\n",
    "        CORR_f = Y_F_combined * np.conjugate(TX_F_combined)\n",
    "        \n",
    "        # 時間領域に戻す\n",
    "        corr_time = ifft(CORR_f, axis=1)\n",
    "\n",
    "        # --- 必要な範囲を切り出し ---\n",
    "        rdresp_single = corr_time[:, P_range]\n",
    "        \n",
    "        # --- 結果保存 ---\n",
    "        rd_maps.append(rdresp_single.copy())\n",
    "        rd_maps.append(i)\n",
    "\n",
    "        # CFAR検出器の利用\n",
    "        radar_in = torch.tensor(abs(rdresp_single)).unsqueeze(0).unsqueeze(0)\n",
    "        detections, _, _ = ca_cfar_2d(radar_in, convert_from_db=False)\n",
    "        idx_est = torch.nonzero(detections[0,0,0], as_tuple=True)[0].tolist()\n",
    "        current_range_idxs, _ = thresholder(radar_in[0,0], idx_est)\n",
    "        \n",
    "        print(\"検出した距離：\", current_range_idxs)\n",
    "        \n",
    "        # 座標変換と結果保存\n",
    "        if len(current_range_idxs) > 0:\n",
    "            print(f\"角度 {current_angle:.2f} 度 のマップからの検出:\")\n",
    "            for r_idx in current_range_idxs:\n",
    "                x_est, y_est, r_est = idx_to_xy(r_idx, current_angle)\n",
    "                detected_objects.append([r_est, current_angle ,x_est, y_est])\n",
    "                print(f\"  -> Index: {r_idx}, Range: {r_est:.2f}m, X: {x_est:.2f}m, Y: {y_est:.2f}m\")\n",
    "        else:\n",
    "            print(f\"ターゲット不検出\")\n",
    "    return detected_objects, rd_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cbe8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD_MAP(rd_maps, frame_id, save_dir=\"./rd_maps/\"):\n",
    "    l_speed = 299792458\n",
    "    Tc = 0.509*1e-9 \n",
    "    f_carrier = 28 * 1e+9\n",
    "    N_trans = 100\n",
    "    T_symbol = 1.115 * 1e-6\n",
    "    \n",
    "    \n",
    "    # ディレクトリがなければ作成\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    rdresp_list = np.array(rd_maps[::2])\n",
    "    idx = np.array(rd_maps[1::2])\n",
    "    \n",
    "    # 距離分解能 (m)\n",
    "    range_res = l_speed * Tc / 2.0\n",
    "    \n",
    "    # 横軸 (距離):\n",
    "    # rdrespの0列目は p-3411 = 0 => p = 3411 (サンプルインデックス)\n",
    "    start_sample_idx = 3411\n",
    "    num_range_bins = 590\n",
    "\n",
    "    r_min = start_sample_idx * range_res\n",
    "    r_max = (start_sample_idx + num_range_bins) * range_res\n",
    "    \n",
    "    v_min_idx = 0\n",
    "    v_max_idx = N_trans # 100\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    print(len(rdresp_list))\n",
    "    for rd_resp in rdresp_list:\n",
    "        print(\"rd_resp shape:\", rd_resp.shape)\n",
    "        #output = rd_resp[:100,:] + 1e-10\n",
    "        output = rd_resp + 1e-10\n",
    "        \n",
    "        plt.imshow(20*np.log10(np.abs(output)), aspect='auto', interpolation='nearest',\n",
    "             extent = [r_min, r_max, v_min_idx, v_max_idx], origin='lower', vmin=-30, vmax = -10)\n",
    "        plt.xlabel('Range [m]')\n",
    "        plt.ylabel('Velocity bin') # 注: DFTのシフトをしていないため、軸の解釈に注意が必要\n",
    "        plt.colorbar(label='Power [dB]')\n",
    "        plt.title('Range-Doppler Map')\n",
    "        plt.grid(False) # 任意\n",
    "        plt.ylim(0,5)\n",
    "        plt.xlim(280,300)\n",
    "        \n",
    "        # --- 保存処理 ---\n",
    "        # ファイル名を決定 (例: ./rd_maps/rd_map_12345.png)\n",
    "        save_path = os.path.join(save_dir, f\"rd_map_{frame_id}_for_{i}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved: {save_path}\")\n",
    "        \n",
    "        # --- クローズ処理 ---\n",
    "        # show() ではなく close() することで、画面表示せずバックグラウンドで処理できます\n",
    "        # 表示もしたい場合は plt.show() の前に plt.savefig() を置いてください\n",
    "        plt.close()\n",
    "        i += 1\n",
    "    \n",
    "    # 保存する\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb065d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvファイルの読み込み機能を関数化\n",
    "def syntax_check(num, idx, y_value, velocity_value, x_pos):\n",
    "    idx_list = np.zeros(num, dtype=np.int32)\n",
    "    position, velocity = np.zeros((num, 3)), np.zeros((num, 3))\n",
    "    i=0\n",
    "    s = set()\n",
    "    while i < num:\n",
    "        # 初期値における距離間隔を保証するための処理\n",
    "        if idx+10 in s or idx-10 in s or idx in s: continue\n",
    "        for j in range(-20,20): s.add(idx+j)\n",
    "        \n",
    "        idx_list[i] = idx\n",
    "        position[i] = np.array([x_pos[idx], y_value, 1])\n",
    "        # v_cy[i] = np.array([np.random.rand(1)[0]*5.56, 0, 0])\n",
    "        velocity[i] = np.array([velocity_value, 0, 0])\n",
    "        \n",
    "        i+=1\n",
    "    return idx_list, position, velocity\n",
    "\n",
    "def get_snapshot_data(cy_idx_target, ve_idx_target,x_pos, p_bs, tx, cy_v_value, ve_v_value, num_cy, num_ve, num_rp):\n",
    "    # Cyclistについて\n",
    "    cy_idx = np.zeros(num_cy, dtype=np.int32)\n",
    "    p_cy, v_cy = np.zeros((num_cy, 3)), np.zeros((num_cy, 3))\n",
    "    # 範囲外アクセスを防ぐための処理\n",
    "    cy_idx, p_cy, v_cy = syntax_check(num_cy, cy_idx_target, 15, cy_v_value, x_pos)\n",
    "    n_cy = len(p_cy)\n",
    "    \n",
    "    # Vehicleについて\n",
    "    ve_idx = np.zeros(num_ve, dtype=np.int32)\n",
    "    p_ve, v_ve = np.zeros((num_ve, 3)), np.zeros((num_ve, 3))\n",
    "    # 範囲外アクセスを防ぐための処理\n",
    "    ve_idx, p_ve, v_ve = syntax_check(num_ve, ve_idx_target, 7.5, ve_v_value, x_pos)\n",
    "    n_ve = len(p_ve)\n",
    "\n",
    "    # ramppostについて\n",
    "    p_rp, v_rp = np.zeros((num_rp, 3)), np.zeros((num_rp, 3))\n",
    "    n_rp = len(p_rp)\n",
    "    \n",
    "    # csvファイルの読み込み\n",
    "    cy_idx += 1\n",
    "    ve_idx += 1\n",
    "\n",
    "    P_rx_cy, tstemp_rx_cy, phase_cy, P_rx_ve, tstemp_rx_ve, phase_ve, P_rx_rp, tstemp_rx_rp, phase_rp = [], [], [], [], [], [], [], [], []\n",
    "    # 3番目のデータから読み込み開始（最初の数個はノイズのみのため）\n",
    "    for i in range(len(cy_idx)):\n",
    "        df = pd.read_csv(\"./ped/0.5nano/complex-impulse-response-Run{:04d}-Sensor_0_Tx_0_to_Rx_0.csv\".format(cy_idx[i]))\n",
    "        tstemp_rx_cy.append(np.ceil((df[\"Time (s)\"]/Tc).values[3:]))                            #サンプル時間で割ることでサンプルインデックスに変換\n",
    "        P_rx_cy.append(df[\"| Total Complex Impulse Response total | (W)\"].values[3:])\n",
    "        phase_cy.append(df['Phase( Total Complex Impulse Response total ) (rad)'].values[3:])\n",
    "    for i in range(len(ve_idx)):\n",
    "        df = pd.read_csv(\"./vehicle/0.5nano/complex-impulse-response-Run{:04d}-Sensor_0_Tx_0_to_Rx_0.csv\".format(ve_idx[i]))\n",
    "        tstemp_rx_ve.append(np.ceil((df[\"Time (s)\"]/Tc).values[3:]))\n",
    "        P_rx_ve.append(df[\"| Total Complex Impulse Response total | (W)\"].values[3:])\n",
    "        phase_ve.append(df['Phase( Total Complex Impulse Response total ) (rad)'].values[3:])\n",
    "    for i in range(1,4):\n",
    "        df = pd.read_csv(\"./Ramposts/\"+str(i)+\"/complex-impulse-response-Run0001-Sensor_0_Tx_0_to_Rx_0.csv\")\n",
    "        tstemp_rx_rp.append(np.ceil((df[\"Time (s)\"]/Tc).values[5:]))\n",
    "        P_rx_rp.append(df[\"| Total Complex Impulse Response total | (W)\"].values[5:])\n",
    "        phase_rp.append(df['Phase( Total Complex Impulse Response total ) (rad)'].values[5:])\n",
    "        \n",
    "    phys_quantities = env.phys_quantities(p_bs, p_cy, v_cy, n_cy, p_ve, v_ve, n_ve, p_rp, v_rp, n_rp)\n",
    "    print(p_cy)\n",
    "    ######### We need some functions here. it is like this. read the csv. this outputs the time stemp and corresponding rx value.\n",
    "    # P_rx_cy_dB = -114\n",
    "    #P_rx_cy_dB = -111\n",
    "    #P_rx_ve_dB = -114\n",
    "    #P_rx_cy_dB = 0\n",
    "    #P_rx_ve_dB = 0\n",
    "    \n",
    "    P_N_dB = -81 # target noise power when using 2GHz BW\n",
    "\n",
    "    sym_duration = rx_sample*Tc\n",
    "\n",
    "    Y = env.rx_multiple(tx, P_rx_cy, tstemp_rx_cy, phase_cy, P_rx_ve, tstemp_rx_ve, phase_ve, P_rx_rp, tstemp_rx_rp, phase_rp, P_N_dB, sym_duration, N_trans)\n",
    "    \n",
    "    return Y, phys_quantities\n",
    "\n",
    "#x_pos = list(np.arange(-450, -149)/10)\n",
    "#p_bs = np.array([250, -18, 50])\n",
    "#Y, phys_quantities = get_snapshot_data(100,0,x_pos,p_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450eb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-37.5  15.    1. ]]\n",
      "Real Range: [293.50681423]\n",
      "Real Velocity: [np.float64(5.877205967159159)]\n",
      "検出した距離： [433]\n",
      "角度 1.59 度 のマップからの検出:\n",
      "  -> Index: 433, Range: 293.29m, X: -38.00m, Y: 7.90m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_0_for_0.png\n",
      "[[-37.2  15.    1. ]]\n",
      "Real Range: [293.21296015]\n",
      "Real Velocity: [np.float64(5.876957141040797)]\n",
      "検出した距離： [426]\n",
      "角度 1.66 度 のマップからの検出:\n",
      "  -> Index: 426, Range: 292.75m, X: -37.43m, Y: 8.20m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_1_for_0.png\n",
      "[[-36.9  15.    1. ]]\n",
      "Real Range: [292.91911853]\n",
      "Real Velocity: [np.float64(5.876707565701734)]\n",
      "検出した距離： [421]\n",
      "角度 1.52 度 のマップからの検出:\n",
      "  -> Index: 421, Range: 292.37m, X: -37.11m, Y: 7.47m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_2_for_0.png\n",
      "[[-36.6  15.    1. ]]\n",
      "Real Range: [292.62528941]\n",
      "Real Velocity: [np.float64(5.8764572381630655)]\n",
      "検出した距離： [414]\n",
      "角度 1.60 度 のマップからの検出:\n",
      "  -> Index: 414, Range: 291.84m, X: -36.53m, Y: 7.82m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_3_for_0.png\n",
      "[[-36.3  15.    1. ]]\n",
      "Real Range: [292.33147282]\n",
      "Real Velocity: [np.float64(5.876206155431227)]\n",
      "検出した距離： [407]\n",
      "角度 1.50 度 のマップからの検出:\n",
      "  -> Index: 407, Range: 291.30m, X: -36.04m, Y: 7.27m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_4_for_0.png\n",
      "[[-36.  15.   1.]]\n",
      "Real Range: [292.0376688]\n",
      "Real Velocity: [np.float64(5.875954314497913)]\n",
      "検出した距離： [401]\n",
      "角度 1.61 度 のマップからの検出:\n",
      "  -> Index: 401, Range: 290.84m, X: -35.53m, Y: 7.78m\n",
      "検出した距離： []\n",
      "ターゲット不検出\n",
      "2\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_5_for_0.png\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_5_for_1.png\n",
      "[[-35.7  15.    1. ]]\n",
      "Real Range: [291.7438774]\n",
      "Real Velocity: [np.float64(5.875701712339994)]\n",
      "検出した距離： [394]\n",
      "角度 1.62 度 のマップからの検出:\n",
      "  -> Index: 394, Range: 290.31m, X: -34.98m, Y: 7.78m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_6_for_0.png\n",
      "[[-35.4  15.    1. ]]\n",
      "Real Range: [291.45009864]\n",
      "Real Velocity: [np.float64(5.875448345919418)]\n",
      "検出した距離： [388]\n",
      "角度 1.56 度 のマップからの検出:\n",
      "  -> Index: 388, Range: 289.85m, X: -34.55m, Y: 7.44m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_7_for_0.png\n",
      "[[-35.1  15.    1. ]]\n",
      "Real Range: [291.15633258]\n",
      "Real Velocity: [np.float64(5.8751942121831355)]\n",
      "検出した距離： [381]\n",
      "角度 1.61 度 のマップからの検出:\n",
      "  -> Index: 381, Range: 289.32m, X: -33.98m, Y: 7.64m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_8_for_0.png\n",
      "[[-34.8  15.    1. ]]\n",
      "Real Range: [290.86257924]\n",
      "Real Velocity: [np.float64(5.874939308063002)]\n",
      "検出した距離： [375]\n",
      "角度 1.69 度 のマップからの検出:\n",
      "  -> Index: 375, Range: 288.86m, X: -33.49m, Y: 7.99m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_9_for_0.png\n",
      "[[-34.5  15.    1. ]]\n",
      "Real Range: [290.56883866]\n",
      "Real Velocity: [np.float64(5.874683630475695)]\n",
      "検出した距離： [368]\n",
      "角度 1.62 度 のマップからの検出:\n",
      "  -> Index: 368, Range: 288.33m, X: -32.98m, Y: 7.60m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_10_for_0.png\n",
      "[[-34.2  15.    1. ]]\n",
      "Real Range: [290.27511089]\n",
      "Real Velocity: [np.float64(5.874427176322623)]\n",
      "検出した距離： [363]\n",
      "角度 1.69 度 のマップからの検出:\n",
      "  -> Index: 363, Range: 287.95m, X: -32.56m, Y: 7.91m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_11_for_0.png\n",
      "[[-33.9  15.    1. ]]\n",
      "Real Range: [289.98139595]\n",
      "Real Velocity: [np.float64(5.874169942489841)]\n",
      "検出した距離： [356]\n",
      "角度 1.67 度 のマップからの検出:\n",
      "  -> Index: 356, Range: 287.41m, X: -32.03m, Y: 7.76m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_12_for_0.png\n",
      "[[-33.6  15.    1. ]]\n",
      "Real Range: [289.68769391]\n",
      "Real Velocity: [np.float64(5.873911925847948)]\n",
      "検出した距離： [350]\n",
      "角度 1.71 度 のマップからの検出:\n",
      "  -> Index: 350, Range: 286.95m, X: -31.55m, Y: 7.92m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_13_for_0.png\n",
      "[[-33.3  15.    1. ]]\n",
      "Real Range: [289.39400478]\n",
      "Real Velocity: [np.float64(5.873653123252007)]\n",
      "検出した距離： [343]\n",
      "角度 1.66 度 のマップからの検出:\n",
      "  -> Index: 343, Range: 286.42m, X: -31.03m, Y: 7.62m\n",
      "検出した距離： []\n",
      "ターゲット不検出\n",
      "2\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_14_for_0.png\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_14_for_1.png\n",
      "[[-33.  15.   1.]]\n",
      "Real Range: [289.10032861]\n",
      "Real Velocity: [np.float64(5.873393531541447)]\n",
      "検出した距離： [336]\n",
      "角度 1.66 度 のマップからの検出:\n",
      "  -> Index: 336, Range: 285.89m, X: -30.49m, Y: 7.57m\n",
      "検出した距離： []\n",
      "ターゲット不検出\n",
      "2\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_15_for_0.png\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_15_for_1.png\n",
      "[[-32.7  15.    1. ]]\n",
      "Real Range: [288.80666544]\n",
      "Real Velocity: [np.float64(5.873133147539979)]\n",
      "検出した距離： [330]\n",
      "角度 1.66 度 のマップからの検出:\n",
      "  -> Index: 330, Range: 285.43m, X: -30.03m, Y: 7.53m\n",
      "検出した距離： []\n",
      "ターゲット不検出\n",
      "2\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_16_for_0.png\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_16_for_1.png\n",
      "[[-32.4  15.    1. ]]\n",
      "Real Range: [288.5130153]\n",
      "Real Velocity: [np.float64(5.8728719680554935)]\n",
      "検出した距離： [323]\n",
      "角度 1.73 度 のマップからの検出:\n",
      "  -> Index: 323, Range: 284.89m, X: -29.46m, Y: 7.82m\n",
      "検出した距離： []\n",
      "ターゲット不検出\n",
      "2\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_17_for_0.png\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_17_for_1.png\n",
      "[[-32.1  15.    1. ]]\n",
      "Real Range: [288.21937825]\n",
      "Real Velocity: [np.float64(5.872609989879969)]\n",
      "検出した距離： [317]\n",
      "角度 1.86 度 のマップからの検出:\n",
      "  -> Index: 317, Range: 284.44m, X: -28.94m, Y: 8.41m\n",
      "1\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_18_for_0.png\n",
      "[[-31.8  15.    1. ]]\n",
      "Real Range: [287.92575432]\n",
      "Real Velocity: [np.float64(5.872347209789386)]\n",
      "検出した距離： [311]\n",
      "角度 1.63 度 のマップからの検出:\n",
      "  -> Index: 311, Range: 283.98m, X: -28.58m, Y: 7.25m\n",
      "検出した距離： []\n",
      "ターゲット不検出\n",
      "2\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_19_for_0.png\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_19_for_1.png\n",
      "[[-31.5  15.    1. ]]\n",
      "Real Range: [287.63214354]\n",
      "Real Velocity: [np.float64(5.872083624543623)]\n",
      "検出した距離： [305]\n",
      "角度 1.81 度 のマップからの検出:\n",
      "  -> Index: 305, Range: 283.52m, X: -28.03m, Y: 8.08m\n",
      "検出した距離： []\n",
      "ターゲット不検出\n",
      "2\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_20_for_0.png\n",
      "rd_resp shape: (100, 590)\n",
      "Saved: ./rd_maps\\rd_map_20_for_1.png\n",
      "\n",
      "Data generation complete.\n",
      "Saved 'measurements.csv'.\n"
     ]
    }
   ],
   "source": [
    "###### symbol time & carrier frequency ######\n",
    "T_symbol = 1.115 * 1e-6              # 一つのチャープ信号の継続時間\n",
    "T_OFDM = 1.0425 * 1e-6\n",
    "f_carrier = 28 * 1e+9               # 搬送波周波数(チャープが使用する周波数帯域の中心)\n",
    "Tc = 0.509*1e-9                      # サンプリング時間(アナログ波形の情報をデジタルデータとして取得する際の時間間隔)\n",
    "\n",
    "###### tx/rx ######\n",
    "N_ant = 16                                      # アンテナの数\n",
    "BW = 1.966080e+9                                # チャープの帯域幅\n",
    "BW_sub = BW/N_ant                               # サブチャープの帯域幅(全アンテナで全帯域幅を分け合う)  \n",
    "N_sample = int(np.floor(T_symbol/Tc))           # 一回のチャープで送信するサンプル数(チャープ信号そのものの長さ)\n",
    "offset = 4000\n",
    "rx_sample = offset + N_sample                   # 一回のチャープで受信するサンプル数(受信バッファの長さ)\n",
    "\n",
    "\n",
    "\n",
    "###### Radar setting ######\n",
    "\n",
    "N_chirp = 100                    # チャープの数\n",
    "mu = BW_sub/T_symbol * 0.98      # チャープの傾き\n",
    "Q = 30                           # 使ってない？\n",
    "Phi = 0.3*np.pi                  # 使ってない？\n",
    "\n",
    "l_speed = 299792458              # 光速\n",
    "\n",
    "N_trans = 100                    # ドップラーDFTの点数(一回の速度計測のために送信するチャープ信号の連射数)\n",
    "\n",
    "refangle = np.arctan(33/265)/2   # 基準角度の設定(cyclist_env_RDA.pyより)\n",
    "\n",
    "\n",
    "env = cyclist_env(f_carrier, N_ant, BW, BW_sub, N_sample, rx_sample, Tc, mu, l_speed)\n",
    "# 送信信号の生成(行列:アンテナ数、列:サンプル数)\n",
    "tx = env.tx()\n",
    "\n",
    "# シミュレーション設定\n",
    "p_bs = np.array([250, -18, 50])                         #基地局の位置\n",
    "\n",
    "# 各車両の数\n",
    "num_cy = 1\n",
    "num_ve = 1\n",
    "num_rp = 0\n",
    "# シミュレーション範囲の設定\n",
    "#start_cy_idx = 135\n",
    "#start_ve_idx = 150\n",
    "start_cy_idx = 75\n",
    "start_ve_idx = 50\n",
    "\n",
    "#end_cy_idx = 300\n",
    "#end_ve_idx = 3\n",
    "end_cy_idx = 135\n",
    "end_ve_idx = 150\n",
    "\n",
    "cy_interval = 3\n",
    "ve_interval = 5\n",
    "\n",
    "cy_v_value = 6\n",
    "ve_v_value = 10\n",
    "\n",
    "cy_idx = start_cy_idx\n",
    "ve_idx = start_ve_idx\n",
    "\n",
    "measurement_history = []\n",
    "frame_count = 0\n",
    "\n",
    "# 繰り返し処理\n",
    "while cy_idx <= end_cy_idx and ve_idx <= end_ve_idx:\n",
    "    x_pos = list(np.arange(-450, -149)/10)                  #x座標のリスト\n",
    "    \n",
    "    Y, phys_quantities = get_snapshot_data(cy_idx,ve_idx,x_pos,p_bs, tx, cy_v_value, ve_v_value, num_cy, num_ve, num_rp)\n",
    "    print(\"Real Range:\", phys_quantities[\"range\"][\"cyclists\"])\n",
    "    print(\"Real Velocity:\", phys_quantities[\"relative_velocity\"][\"cyclists\"])\n",
    "    #est_ang = MUSIC_method(Y, N_ant)\n",
    "    est_ang = MUSIC_method_improved(Y, N_ant, num_cy + num_ve + num_rp)\n",
    "    #est_ang = Root_MUSIC_method(Y, N_ant, num_cy + num_ve + num_rp)\n",
    "    \n",
    "    #detected_objects, rd_maps = DFT(N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang)\n",
    "    detected_objects, rd_maps = FFT(N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang)\n",
    "    #plot_rd_maps(rd_maps, est_ang)\n",
    "    RD_MAP(rd_maps, frame_count, save_dir=\"./rd_maps\")\n",
    "    \n",
    "    if len(detected_objects) > 0:\n",
    "        for obj in detected_objects:\n",
    "            measurement_history.append({\n",
    "                \"Time\": frame_count,  # 時刻（フレーム番号）\n",
    "                \"Range\": obj[0],      # 距離 [m]\n",
    "                \"Angle\": obj[1],      # 角度 [度]\n",
    "                \"X\": obj[2],          # X座標 [m]\n",
    "                \"Y\": obj[3]           # Y座標 [m]\n",
    "            })\n",
    "    else:\n",
    "        # 何も検出されなかった場合も、時刻だけ記録したい場合は以下のようにNaNを入れる\n",
    "        # (不要であればこのelseブロックは削除してください)\n",
    "        measurement_history.append({\n",
    "            \"Time\": frame_count,\n",
    "            \"Range\": np.nan,\n",
    "            \"Angle\": np.nan,\n",
    "            \"X\": np.nan,\n",
    "            \"Y\": np.nan\n",
    "        })\n",
    "    \n",
    "    cy_idx += cy_interval\n",
    "    ve_idx += ve_interval\n",
    "    frame_count += 1\n",
    "    \n",
    "# csvファイルに保存\n",
    "# --- 6. CSVへの保存 ---\n",
    "df_measurements = pd.DataFrame(measurement_history)\n",
    "\n",
    "# 保存\n",
    "csv_filename = \"measurements.csv\"\n",
    "df_measurements.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(\"\\nData generation complete.\")\n",
    "print(f\"Saved '{csv_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "287f10e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合計 32 枚の画像が見つかりました。\n",
      "50 枚ごとに分割してGIFを作成します。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kousu\\AppData\\Local\\Temp\\ipykernel_24128\\3459896525.py:50: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Saved: rd_map_animation_part01.gif (i=0 to 1)\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "\n",
    "def create_split_gifs(image_folder, output_prefix, frames_per_gif=100, duration=0.1):\n",
    "    \"\"\"\n",
    "    指定した枚数ごとにGIFを分割して作成します。\n",
    "    \n",
    "    image_folder: 画像フォルダ\n",
    "    output_prefix: 出力ファイル名の接頭辞 (例: \"radar_movie\") -> \"radar_movie_part1.gif\" になります\n",
    "    frames_per_gif: 1つのGIFに含める画像の枚数 (iがこの数増えるごとに新しいGIFを作ります)\n",
    "    duration: フレーム速度\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 画像ファイルの取得\n",
    "    search_path = os.path.join(image_folder, \"*.png\")\n",
    "    files = glob.glob(search_path)\n",
    "    \n",
    "    if not files:\n",
    "        print(\"画像が見つかりませんでした。\")\n",
    "        return\n",
    "\n",
    "    # 2. ファイル名 \"rd_map_{id}_for_{i}.png\" の {i} を基準にソート\n",
    "    def get_sort_key(filepath):\n",
    "        try:\n",
    "            filename = os.path.basename(filepath)\n",
    "            # \"_for_\" の後ろの数字を取得\n",
    "            return int(filename.split('_for_')[-1].replace('.png', ''))\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    files.sort(key=get_sort_key)\n",
    "    \n",
    "    total_files = len(files)\n",
    "    print(f\"合計 {total_files} 枚の画像が見つかりました。\")\n",
    "    print(f\"{frames_per_gif} 枚ごとに分割してGIFを作成します。\")\n",
    "\n",
    "    # 3. 分割してGIF作成\n",
    "    # 0からtotal_filesまで、frames_per_gif ずつステップしてループ\n",
    "    num_parts = math.ceil(total_files / frames_per_gif)\n",
    "    \n",
    "    for part_idx, start_idx in enumerate(range(0, total_files, frames_per_gif)):\n",
    "        # 今回のバッチ処理するファイルリストをスライス\n",
    "        end_idx = start_idx + frames_per_gif\n",
    "        batch_files = files[start_idx : end_idx]\n",
    "        \n",
    "        images = []\n",
    "        for filename in batch_files:\n",
    "            images.append(imageio.imread(filename))\n",
    "            \n",
    "        # ファイル名を決定 (例: radar_movie_part01.gif)\n",
    "        # part_idx + 1 にして 1から始まる番号にします\n",
    "        output_name = f\"{output_prefix}_part{part_idx + 1:02d}.gif\"\n",
    "        \n",
    "        imageio.mimsave(output_name, images, duration=duration, loop=0)\n",
    "        \n",
    "        # 進捗表示\n",
    "        first_i = get_sort_key(batch_files[0])\n",
    "        last_i = get_sort_key(batch_files[-1])\n",
    "        print(f\"[{part_idx + 1}/{num_parts}] Saved: {output_name} (i={first_i} to {last_i})\")\n",
    "\n",
    "# --- 実行設定 ---\n",
    "target_folder = \"./rd_maps/\" \n",
    "\n",
    "# ここで「何枚ごとに1つのGIFにするか」を設定します\n",
    "# 例: 50枚ごとに区切るなら 50 を指定\n",
    "create_split_gifs(\n",
    "    image_folder=target_folder, \n",
    "    output_prefix=\"rd_map_animation\", \n",
    "    frames_per_gif=50,  # <--- ここで枚数を調整\n",
    "    duration=0.1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
