{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77042693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Cyclist_env_RDA import cyclist_env\n",
    "from time import time\n",
    "from scipy.linalg import dft\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac10d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CFAR検出器の実装\n",
    "\n",
    "def ca_cfar_2d(x_db, n_train=(1,7), n_guard=(1,5), pfa=1e-6, convert_from_db=False):\n",
    "    \"\"\"\n",
    "    x_db: (B,1,H,W) input map (dB or linear)\n",
    "    n_train: (th, tw) training half window size\n",
    "    n_guard: (gh, gw) guard half window size\n",
    "    \"\"\"\n",
    "    if convert_from_db:\n",
    "        x = 10 ** (x_db / 10.0)  # dB -> linear\n",
    "    else:\n",
    "        x = x_db\n",
    "\n",
    "    B, C, H, W = x.shape\n",
    "    th, tw = n_train\n",
    "    gh, gw = n_guard\n",
    "\n",
    "    # Total kernel size\n",
    "    kh = 2 * (th + gh) + 1\n",
    "    kw = 2 * (tw + gw) + 1\n",
    "\n",
    "    # Make training mask\n",
    "    kernel = torch.ones((1,1,kh,kw), device=x.device)\n",
    "    kernel[:, :, th-gh:th+gh+1, tw-gw:tw+gw+1] = 0  # guard + CUT = 0\n",
    "\n",
    "    N_train = kernel.sum().item()\n",
    "    alpha = N_train * (pfa ** (-1.0 / N_train) - 1.0)\n",
    "\n",
    "    # Convolution = training sum\n",
    "    x_pad = F.pad(x, (kw//2, kw//2, kh//2, kh//2), mode=\"reflect\")\n",
    "    train_sum = F.conv2d(x_pad.double(), kernel.double())\n",
    "    noise_est = train_sum / N_train\n",
    "\n",
    "    threshold = alpha * noise_est\n",
    "    detections = x > threshold\n",
    "    return detections, threshold, noise_est\n",
    "\n",
    "# 変更前: tar_thres = -25\n",
    "# 変更後: tar_thres = -35  (または -30)\n",
    "def thresholder(radar, idx_est, tar_thres = -25, cyvethres = 2.638):\n",
    "    cy_idx, ve_idx = [], []\n",
    "    radar = 20*torch.log10(radar)\n",
    "    for i in range(len(idx_est)):\n",
    "        rangeofinterest = radar[:5, max(0, idx_est[i]-5):min(idx_est[i]+5, 589)].flatten()\n",
    "        top2 = rangeofinterest.topk(2).values.mean()\n",
    "        if top2 > tar_thres:\n",
    "            cy_idx.append(idx_est[i])\n",
    "            ve_idx.append(idx_est[i]) \n",
    "\n",
    "    cy_idx_cleans = cleansing(cy_idx)\n",
    "    ve_idx_cleans = cleansing(ve_idx)\n",
    "\n",
    "    return cy_idx_cleans, ve_idx_cleans\n",
    "    \n",
    "def cleansing(idx, tol = 5):\n",
    "    if idx :\n",
    "        res = [idx[0]]\n",
    "        for i in range(1,len(idx)):\n",
    "            if idx[i]<=idx[i-1]+5:\n",
    "                continue\n",
    "            res.append(idx[i])\n",
    "        return res\n",
    "    else: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02bd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stevec(N_ant, angle):\n",
    "    resp = (np.arange(N_ant)-N_ant*0.5+0.5).reshape([-1,1])\n",
    "    resp = np.exp(1j*resp*np.pi*np.sin(angle))\n",
    "    return np.matrix(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb065d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvファイルの読み込み機能を関数化\n",
    "def syntax_check(num, idx, y_value, velocity_value, x_pos):\n",
    "    idx_list = np.zeros(num, dtype=np.int32)\n",
    "    position, velocity = np.zeros((num, 3)), np.zeros((num, 3))\n",
    "    i=0\n",
    "    s = set()\n",
    "    while i < num:\n",
    "        # 初期値における距離間隔を保証するための処理\n",
    "        if idx+10 in s or idx-10 in s or idx in s: continue\n",
    "        for j in range(-20,20): s.add(idx+j)\n",
    "        \n",
    "        idx_list[i] = idx\n",
    "        position[i] = np.array([x_pos[idx], y_value, 1])\n",
    "        # v_cy[i] = np.array([np.random.rand(1)[0]*5.56, 0, 0])\n",
    "        velocity[i] = np.array([velocity_value, 0, 0])\n",
    "        \n",
    "        i+=1\n",
    "    return idx_list, position, velocity\n",
    "\n",
    "def get_snapshot_data(cy_idx_target, ve_idx_target,x_pos, p_bs, tx, cy_v_value, ve_v_value, num_cy, num_ve, num_rp):\n",
    "    # Cyclistについて\n",
    "    cy_idx = np.zeros(num_cy, dtype=np.int32)\n",
    "    p_cy, v_cy = np.zeros((num_cy, 3)), np.zeros((num_cy, 3))\n",
    "    # 範囲外アクセスを防ぐための処理\n",
    "    cy_idx, p_cy, v_cy = syntax_check(num_cy, cy_idx_target, 15, cy_v_value, x_pos)\n",
    "    n_cy = len(p_cy)\n",
    "    \n",
    "    # Vehicleについて\n",
    "    ve_idx = np.zeros(num_ve, dtype=np.int32)\n",
    "    p_ve, v_ve = np.zeros((num_ve, 3)), np.zeros((num_ve, 3))\n",
    "    # 範囲外アクセスを防ぐための処理\n",
    "    ve_idx, p_ve, v_ve = syntax_check(num_ve, ve_idx_target, 7.5, ve_v_value, x_pos)\n",
    "    n_ve = len(p_ve)\n",
    "\n",
    "    # ramppostについて\n",
    "    p_rp, v_rp = np.zeros((num_rp, 3)), np.zeros((num_rp, 3))\n",
    "    n_rp = len(p_rp)\n",
    "    \n",
    "    # csvファイルの読み込み\n",
    "    cy_idx += 1\n",
    "    ve_idx += 1\n",
    "\n",
    "    P_rx_cy, tstemp_rx_cy, phase_cy, P_rx_ve, tstemp_rx_ve, phase_ve, P_rx_rp, tstemp_rx_rp, phase_rp = [], [], [], [], [], [], [], [], []\n",
    "    for i in range(len(cy_idx)):\n",
    "        df = pd.read_csv(\"./ped/0.5nano/complex-impulse-response-Run{:04d}-Sensor_0_Tx_0_to_Rx_0.csv\".format(cy_idx[i]))\n",
    "        tstemp_rx_cy.append(np.ceil((df[\"Time (s)\"]/Tc).values[3:]))\n",
    "        P_rx_cy.append(df[\"| Total Complex Impulse Response total | (W)\"].values[3:])\n",
    "        phase_cy.append(df['Phase( Total Complex Impulse Response total ) (rad)'].values[3:])\n",
    "    for i in range(len(ve_idx)):\n",
    "        df = pd.read_csv(\"./vehicle/0.5nano/complex-impulse-response-Run{:04d}-Sensor_0_Tx_0_to_Rx_0.csv\".format(ve_idx[i]))\n",
    "        tstemp_rx_ve.append(np.ceil((df[\"Time (s)\"]/Tc).values[3:]))\n",
    "        P_rx_ve.append(df[\"| Total Complex Impulse Response total | (W)\"].values[3:])\n",
    "        phase_ve.append(df['Phase( Total Complex Impulse Response total ) (rad)'].values[3:])\n",
    "    for i in range(1,4):\n",
    "        df = pd.read_csv(\"./Ramposts/\"+str(i)+\"/complex-impulse-response-Run0001-Sensor_0_Tx_0_to_Rx_0.csv\")\n",
    "        tstemp_rx_rp.append(np.ceil((df[\"Time (s)\"]/Tc).values[5:]))\n",
    "        P_rx_rp.append(df[\"| Total Complex Impulse Response total | (W)\"].values[5:])\n",
    "        phase_rp.append(df['Phase( Total Complex Impulse Response total ) (rad)'].values[5:])\n",
    "        \n",
    "    phys_quantities = env.phys_quantities(p_bs, p_cy, v_cy, n_cy, p_ve, v_ve, n_ve, p_rp, v_rp, n_rp)\n",
    "    \n",
    "    \n",
    "    ######### We need some functions here. it is like this. read the csv. this outputs the time stemp and corresponding rx value.\n",
    "    # P_rx_cy_dB = -114\n",
    "    #P_rx_cy_dB = -111\n",
    "    #P_rx_ve_dB = -114\n",
    "    #P_rx_cy_dB = 0\n",
    "    #P_rx_ve_dB = 0\n",
    "    \n",
    "    P_N_dB = -81 # target noise power when using 2GHz BW\n",
    "\n",
    "    sym_duration = rx_sample*Tc\n",
    "\n",
    "    Y = env.rx_multiple(tx, P_rx_cy, tstemp_rx_cy, phase_cy, P_rx_ve, tstemp_rx_ve, phase_ve, P_rx_rp, tstemp_rx_rp, phase_rp, P_N_dB, sym_duration, N_trans)\n",
    "    #print(\"Cyclelist and Vehicle positions:\")\n",
    "    #print(p_cy)\n",
    "    #print(p_ve)\n",
    "    return Y, phys_quantities\n",
    "\n",
    "#x_pos = list(np.arange(-450, -149)/10)\n",
    "#p_bs = np.array([250, -18, 50])\n",
    "#Y, phys_quantities = get_snapshot_data(100,0,x_pos,p_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084e05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_method(Y, N_ant):\n",
    "    Y_music = np.mean(Y, axis=0)\n",
    "    R_yy = Y_music@np.conjugate(np.transpose(Y_music))\n",
    "    # print(np.linalg.eig(R_yy)[0])\n",
    "    U = np.linalg.eig(R_yy)[1][:,5:]\n",
    "\n",
    "    resp = []\n",
    "    argm = (np.arange(1800)-900)/100\n",
    "    for val in argm:\n",
    "        stv = stevec(N_ant, val*np.pi/180)\n",
    "        p = stv.T@U\n",
    "        pp = p*np.conjugate(np.transpose(p))\n",
    "        resp.append(1/(np.abs(pp)**2).A1)\n",
    "\n",
    "    M = max(resp)\n",
    "    est_ang = []\n",
    "    \n",
    "    a, b = resp[0][0], resp[1][0]\n",
    "    for i in range(1,len(argm)-1):\n",
    "        c = resp[i+1][0]\n",
    "        if a < b and b > c and b > 0.2 * M:\n",
    "            est_ang.append(argm[i])\n",
    "        a, b = b, c\n",
    "    return est_ang\n",
    "\n",
    "#angle_list = MUSIC_method(Y)\n",
    "#print(\"Estimated angles:\", angle_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb3c75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_method_Debug(eig_val, N_ant, num_signals, resp, argm, M):\n",
    "    \"\"\"\n",
    "    MUSIC法の状態を診断するためのデバッグ関数\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"【MUSIC法 デバッグ情報】\")\n",
    "    \n",
    "    # --- 1. 数値情報の出力 ---\n",
    "    # 固有値の絶対値（大きい順）\n",
    "    eig_abs = np.abs(eig_val)\n",
    "    print(f\"1. 固有値 (大きい順):\\n{eig_abs}\")\n",
    "    \n",
    "    # 推定された信号数と閾値情報\n",
    "    print(f\"2. 設定信号数 (K): {num_signals}\")\n",
    "    print(f\"3. スペクトル最大値 (M): {M:.2e}\")\n",
    "    print(f\"4. 現在の閾値 (20%): {0.2 * M:.2e}\")\n",
    "\n",
    "    # --- 2. グラフ描画 (重要) ---\n",
    "    try:\n",
    "        # プロットエリアを2つ作成 (左: 固有値分布, 右: MUSICスペクトル)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # === 左のグラフ: 固有値分布 (Scree Plot) ===\n",
    "        # これを見ることで、信号がノイズから分離できているか確認できます\n",
    "        ax1.plot(range(1, len(eig_abs) + 1), eig_abs, 'bo-', markersize=8)\n",
    "        ax1.set_title('Eigenvalue Distribution (Scree Plot)')\n",
    "        ax1.set_xlabel('Index')\n",
    "        ax1.set_ylabel('Eigenvalue (log scale)')\n",
    "        ax1.set_yscale('log') # 固有値は桁が違うことが多いので対数がおすすめ\n",
    "        ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "        \n",
    "        # 信号部分とノイズ部分の境界に線を引く\n",
    "        ax1.axvline(x=num_signals + 0.5, color='r', linestyle='--', label=f'Separation (K={num_signals})')\n",
    "        ax1.legend()\n",
    "\n",
    "        # === 右のグラフ: MUSICスペクトル ===\n",
    "        # どこにピークがあり、閾値でどう切られているか確認します\n",
    "        resp_array = np.array(resp).flatten() # 形状を1次元に統一\n",
    "        \n",
    "        ax2.plot(argm, resp_array, label='MUSIC Spectrum')\n",
    "        ax2.set_title(f'MUSIC Spectrum (N_ant={N_ant}, K={num_signals})')\n",
    "        ax2.set_xlabel('Angle [deg]')\n",
    "        ax2.set_ylabel('Spectrum Power')\n",
    "        ax2.set_yscale('log') # スペクトルも対数で見ると弱いピークが見つけやすい\n",
    "        ax2.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "        \n",
    "        # 閾値の線を引く (赤の点線)\n",
    "        threshold_val = 0.2 * M\n",
    "        ax2.axhline(y=threshold_val, color='r', linestyle='--', label='Threshold (20%)')\n",
    "        \n",
    "        # もし閾値を5%に下げたらどう見えるかも参考として表示 (緑の点線)\n",
    "        ax2.axhline(y=0.05 * M, color='g', linestyle=':', label='Threshold (5%)')\n",
    "        \n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"-> 診断用グラフを描画しました\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"-> グラフ描画中にエラーが発生しました: {e}\")\n",
    "        \n",
    "    print(\"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea60054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MUSIC_method_improved(Y, N_ant, num_signals):\n",
    "    Y_music = np.mean(Y, axis=0)\n",
    "    R_yy = Y_music@np.conjugate(np.transpose(Y_music))\n",
    "    # 1.固有値分解\n",
    "    eig_val, eig_vec = np.linalg.eig(R_yy)\n",
    "\n",
    "    # 2.固有値をソートして雑音部分空間を取得\n",
    "    idx = np.abs(eig_val).argsort()[::-1]\n",
    "    # インデックスによって固有値と固有ベクトルの対応関係を維持しつつソート\n",
    "    eig_val = eig_val[idx]\n",
    "    eig_vec = eig_vec[:, idx]\n",
    "    # 雑音部分空間Uを取得\n",
    "\n",
    "    # num_signalsを固有値から推定?\n",
    "    \n",
    "    # デバッグ用\n",
    "    #num_signals = 1\n",
    "    \n",
    "    U = eig_vec[:, num_signals:]\n",
    "\n",
    "    # 3.雑音部分空間とvalごとのステアリングベクトルの内積を計算\n",
    "    resp = []\n",
    "    argm = (np.arange(1800)-900)/100\n",
    "    for val in argm:\n",
    "        # ステアリングベクトルの計算\n",
    "        stv = stevec(N_ant, val*np.pi/180)\n",
    "        # 雑音部分空間との内積\n",
    "        p = stv.T@U\n",
    "        # L2ノルムの二乗を計算(pp^H)\n",
    "        pp = p*np.conjugate(np.transpose(p))\n",
    "        # A1は行列を1次元配列に変換するメソッド\n",
    "        # respに逆数を追加\n",
    "        # 分子は角度推定の上では不要なので省略している\n",
    "        resp.append(1/(np.abs(pp)**2).A1)\n",
    "\n",
    "    # 4.ピーク検出\n",
    "    M = np.max(resp)\n",
    "    \n",
    "    # デバッグ用\n",
    "    MUSIC_method_Debug(eig_val, N_ant, num_signals, resp, argm, M)\n",
    "    \n",
    "    est_ang = []\n",
    "    # 三点比較によるピーク検出\n",
    "    a, b = resp[0][0], resp[1][0]\n",
    "    for i in range(1,len(argm)-1):\n",
    "        c = resp[i+1][0]\n",
    "        if a < b and b > c and b > 0.2 * M:\n",
    "        #if a < b and b > c and b > 0.05 * M:\n",
    "            est_ang.append(argm[i])\n",
    "        a, b = b, c\n",
    "    return est_ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6383220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Root_MUSIC_method(Y, N_ant, num_signals):\n",
    "    Y_music = np.mean(Y, axis=0)\n",
    "    R_yy = Y_music@np.conjugate(np.transpose(Y_music))\n",
    "    # 1.固有値分解\n",
    "    eig_val, eig_vec = np.linalg.eig(R_yy)\n",
    "\n",
    "    # 2.固有値をソートして雑音部分空間を取得\n",
    "    idx = np.abs(eig_val).argsort()[::-1]\n",
    "    # インデックスによって固有値と固有ベクトルの対応関係を維持しつつソート\n",
    "    eig_val = eig_val[idx]\n",
    "    eig_vec = eig_vec[:, idx]\n",
    "    # 雑音部分空間Uを取得\n",
    "\n",
    "    # num_signalsを固有値から推定?\n",
    "    \n",
    "    # デバッグ用\n",
    "    #num_signals = 5\n",
    "    \n",
    "    U = eig_vec[:, num_signals:]\n",
    "    # --- Root-MUSIC 特有の処理 ---\n",
    "    # 行列 C = U * U^H を計算\n",
    "    C = U @ U.T.conj()\n",
    "    \n",
    "    # 行列Cの対角線の和（係数）を計算\n",
    "    # 対角線ごとに足し合わせて多項式の係数を作ります\n",
    "    coeff = np.zeros((2 * N_ant - 1,), dtype=complex)\n",
    "    for i in range(N_ant):\n",
    "        for j in range(N_ant):\n",
    "            coeff[i - j + (N_ant - 1)] += C[i, j]\n",
    "\n",
    "    # 多項式の根（Roots）を求める\n",
    "    roots = np.roots(coeff)\n",
    "    \n",
    "    # 単位円の内側で、かつ単位円に近い根をK個探す\n",
    "    # 1. 単位円上の根は振幅が1なので、絶対値が1に近いものを探す\n",
    "    # 2. 安定性のため単位円の内側(|z| <= 1)の根を選ぶことが多い\n",
    "    \n",
    "    # 半径1に近い順にソート（ただしノイズの影響で1を超えることもあるので工夫が必要）\n",
    "    # 一般的には |z| < 1 の中で |z| が大きい順（円に近い順）にK個選ぶ\n",
    "    roots = roots[np.abs(roots) <= 1.0] # 単位円内側のみ\n",
    "    idx = np.argsort(np.abs(roots))[::-1] # 絶対値が大きい順（円に近い順）\n",
    "    est_roots = roots[idx[:num_signals]] # 上位K個を取得\n",
    "    \n",
    "    # 根から角度に変換: z = exp(j * 2pi * d/lambda * sin(theta))\n",
    "    # arg(z) = 2pi * d/lambda * sin(theta)\n",
    "    # sin(theta) = arg(z) / (2pi * d/lambda)\n",
    "    # 通常 d = lambda/2 なので、 sin(theta) = arg(z) / pi\n",
    "    \n",
    "    est_ang_rad = np.arcsin(np.angle(est_roots) / np.pi)\n",
    "    est_ang_deg = np.degrees(est_ang_rad)\n",
    "    \n",
    "    return np.sort(est_ang_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3681e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bs = np.array([250, -18, 50])\n",
    "\n",
    "def idx_to_xy(range_idx, angle_deg):\n",
    "    \"\"\"\n",
    "    range_idx: cy_idxs_pred の値 (例: 496)\n",
    "    angle_deg: MUSIC法で推定した角度 [度] (例: est_ang[0])\n",
    "    \"\"\"\n",
    "    offset = 3411\n",
    "    # (1) 距離の計算 [m]\n",
    "    # サンプル番号 = インデックス + オフセット\n",
    "    sample_idx = range_idx + offset\n",
    "    # 往復時間 = サンプル番号 * Tc\n",
    "    # 距離 = 往復時間 * c / 2\n",
    "    R = (sample_idx * Tc * env.c) / 2\n",
    "\n",
    "    # 三次元距離を二次元距離に変換\n",
    "    height_diff = p_bs[2] - 1\n",
    "    if R > height_diff:\n",
    "        R_horizontal = np.sqrt(R**2 - height_diff**2)\n",
    "    else:\n",
    "        R_horizontal = 0\n",
    "\n",
    "    # (2) 角度の計算 [rad]\n",
    "    # 推定角度をラジアンに変換し、基準角度(refangle)を足す\n",
    "    # anglecalの逆演算: cy_ang = arctan(...) - refangle なので\n",
    "    # arctan(...) = cy_ang + refangle\n",
    "    theta_world = np.deg2rad(angle_deg) + refangle\n",
    "\n",
    "    # (3) XY座標の計算 [m]\n",
    "    # 基地局(p_bs)からの相対位置\n",
    "    # cy_denum (dx) = R * cos(theta)\n",
    "    # cy_nu (dy) = R * sin(theta)\n",
    "    dx = R_horizontal * np.cos(theta_world)\n",
    "    dy = R_horizontal * np.sin(theta_world)\n",
    "\n",
    "    # 世界座標（絶対座標）に変換\n",
    "    # cy_denum = bs[0] - cy[0]  =>  cy[0] = bs[0] - dx\n",
    "    # cy_nu    = cy[1] - bs[1]  =>  cy[1] = bs[1] + dy\n",
    "    x = p_bs[0] - dx\n",
    "    y = p_bs[1] + dy\n",
    "\n",
    "    return x, y, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9fb3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFT (N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang):\n",
    "    Dopp_dft = dft(N_trans)/np.sqrt(N_trans)\n",
    "    Y_dft = np.zeros((N_trans, N_ant, rx_sample), dtype=np.complex128)\n",
    "    for i in range(N_ant):\n",
    "        Y_dft[:,i,:] = Dopp_dft@Y[:,i,:]\n",
    "    val, res, rdresp = 0, [], np.zeros((N_trans,590), dtype=np.complex128)\n",
    "    Q = 1\n",
    "\n",
    "    # 結果を保存するリスト\n",
    "    detected_objects = []\n",
    "    \n",
    "    P_range = np.arange(590)+3411\n",
    "    #P_range = np.arange(150) + 3800\n",
    "    for i in range(len(est_ang)):\n",
    "        current_angle = est_ang[i]\n",
    "        #  他の角度の結果と混ざらないように rdresp_single を使う\n",
    "        rdresp_single = np.zeros((N_trans, 590), dtype=np.complex128)\n",
    "        ang_rad = current_angle * np.pi / 180\n",
    "        dup = np.ones((N_trans, 1, 1), dtype=np.complex128)\n",
    "        \n",
    "        for p in P_range: # レンジ方向のループ\n",
    "            # ... (既存の信号生成・相関処理 tx, stevec など) ...\n",
    "            X_cand = np.zeros((N_ant, rx_sample), dtype=np.complex128)\n",
    "            last = min(p+N_sample, rx_sample)\n",
    "            X_cand[:,p:last] += tx[:,:last-p]\n",
    "            g = np.conjugate(stevec(N_ant, ang_rad))@np.conjugate(np.transpose(stevec(N_ant, ang_rad)))@X_cand\n",
    "            g_mat = dup*np.array(g)\n",
    "            metric = np.sum(np.multiply(np.conjugate(Y_dft), g_mat), axis=(1,2))\n",
    "            \n",
    "            # ここで rdresp ではなく rdresp_single に保存\n",
    "            rdresp_single[:, p-3411] = metric\n",
    "            \n",
    "        # CFAR検出器の利用\n",
    "        radar_in = torch.tensor(abs(rdresp_single)).unsqueeze(0).unsqueeze(0)\n",
    "        detections, _, _ = ca_cfar_2d(radar_in, convert_from_db=False)\n",
    "        idx_est = torch.nonzero(detections[0,0,0], as_tuple=True)[0].tolist()\n",
    "        current_range_idxs, _ = thresholder(radar_in[0,0], idx_est)\n",
    "        \n",
    "        print(\"検出した距離：\", current_range_idxs)\n",
    "        \n",
    "        # 座標変換と結果保存\n",
    "        if len(current_range_idxs) > 0:\n",
    "            print(f\"角度 {current_angle:.2f} 度 のマップからの検出:\")\n",
    "            for r_idx in current_range_idxs:\n",
    "                x_est, y_est, r_est = idx_to_xy(r_idx, current_angle)\n",
    "                detected_objects.append([r_est, current_angle ,x_est, y_est])\n",
    "                print(f\"  -> Index: {r_idx}, Range: {r_est:.2f}m, X: {x_est:.2f}m, Y: {y_est:.2f}m\")\n",
    "        else:\n",
    "            print(f\"ターゲット不検出\")\n",
    "    return detected_objects\n",
    "\n",
    "#Y, phys_quantities = get_snapshot_data(100,0)\n",
    "#est_ang = MUSIC_method(Y)\n",
    "#detected_objects = DFT(N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang)\n",
    "#print(\"Detected objects (X, Y):\", detected_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450eb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug\n",
      "[-2.73848569 -1.48871082]\n",
      "Debug\n",
      "[-2.81028749 -1.45712239]\n",
      "Debug\n",
      "[-2.99759961 -1.56101315]\n",
      "Debug\n",
      "[-2.92497005 -1.56692848]\n",
      "Debug\n",
      "[-2.99340853 -1.65760858]\n",
      "Debug\n",
      "[-3.09282859 -1.60916568]\n",
      "Debug\n",
      "[-3.10097194 -1.56763774]\n",
      "Debug\n",
      "[-2.82133775 -1.60167609]\n",
      "Debug\n",
      "[-2.94118661 -1.58874202]\n",
      "Debug\n",
      "[-3.19243041 -1.64451063]\n",
      "Debug\n",
      "[-2.98984103 -1.62740042]\n",
      "Debug\n",
      "[-2.92665271 -1.5775605 ]\n",
      "Debug\n",
      "[-3.10397653 -1.66438707]\n",
      "Debug\n",
      "[-3.07656003 -1.59574371]\n",
      "Debug\n",
      "[-2.85080911 -1.49427154]\n",
      "Debug\n",
      "[-3.0710888  -1.78240486]\n",
      "Debug\n",
      "[-3.05817377 -1.81629491]\n",
      "Debug\n",
      "[-3.09862525 -1.62675013]\n",
      "Debug\n",
      "[-2.95199869 -1.70741762]\n",
      "Debug\n",
      "[-2.98822044 -1.71688772]\n",
      "Debug\n",
      "[-2.89938603 -1.63106455]\n",
      "\n",
      "Data generation complete.\n",
      "Saved 'measurements.csv'.\n"
     ]
    }
   ],
   "source": [
    "###### symbol time & carrier frequency ######\n",
    "T_symbol = 1.115 * 1e-6              # symbol duration, with CP time\n",
    "T_OFDM = 1.0425 * 1e-6\n",
    "f_carrier = 28 * 1e+9\n",
    "Tc = 0.509*1e-9                      # sampling time\n",
    "\n",
    "###### tx/rx ######\n",
    "N_ant = 16                       # the number of antennas\n",
    "BW = 1.966080e+9                      # chirp bandwidth\n",
    "BW_sub = BW/N_ant\n",
    "N_sample = int(np.floor(T_symbol/Tc))           # the number of samples of single chirp\n",
    "offset = 4000\n",
    "rx_sample = offset + N_sample\n",
    "\n",
    "\n",
    "\n",
    "###### Radar setting ######\n",
    "\n",
    "N_chirp = 100                    # the number of chirps\n",
    "mu = BW_sub/T_symbol * 0.98\n",
    "Q = 30\n",
    "Phi = 0.3*np.pi\n",
    "\n",
    "l_speed = 299792458\n",
    "\n",
    "N_trans = 100\n",
    "\n",
    "refangle = np.arctan(33/265)/2 # 基準角度の設定(cyclist_env_RDA.pyより)\n",
    "\n",
    "\n",
    "env = cyclist_env(f_carrier, N_ant, BW, BW_sub, N_sample, rx_sample, Tc, mu, l_speed)\n",
    "tx = env.tx()\n",
    "\n",
    "# シミュレーション設定\n",
    "num_cy = 1\n",
    "num_ve = 0\n",
    "num_rp = 0\n",
    "\n",
    "#start_cy_idx = 300\n",
    "#start_ve_idx = 3\n",
    "start_cy_idx = 75\n",
    "start_ve_idx = 50\n",
    "\n",
    "#end_cy_idx = 300\n",
    "#end_ve_idx = 3\n",
    "end_cy_idx = 135\n",
    "end_ve_idx = 150\n",
    "\n",
    "cy_interval = 2\n",
    "ve_interval = 5\n",
    "\n",
    "cy_v_value = 6\n",
    "ve_v_value = 10\n",
    "\n",
    "cy_idx = start_cy_idx\n",
    "ve_idx = start_ve_idx\n",
    "\n",
    "measurement_history = []\n",
    "frame_count = 0\n",
    "\n",
    "# 繰り返し処理\n",
    "while cy_idx <= end_cy_idx and ve_idx <= end_ve_idx:\n",
    "    print(\"Debug\")\n",
    "    x_pos = list(np.arange(-450, -149)/10)\n",
    "    p_bs = np.array([250, -18, 50])\n",
    "    Y, phys_quantities = get_snapshot_data(cy_idx,ve_idx,x_pos,p_bs, tx, cy_v_value, ve_v_value, num_cy, num_ve, num_rp)\n",
    "    #est_ang = MUSIC_method(Y, N_ant)\n",
    "    est_ang = MUSIC_method_improved(Y, N_ant, num_cy + num_ve + num_rp)\n",
    "    #est_ang = Root_MUSIC_method(Y, N_ant, num_cy + num_ve + num_rp)\n",
    "    print(est_ang)\n",
    "    \n",
    "    detected_objects = DFT(N_trans, N_ant, rx_sample, Y, tx, N_sample, est_ang)\n",
    "    print(\"Detected objects (X, Y):\", detected_objects)\n",
    "    \n",
    "    if len(detected_objects) > 0:\n",
    "        for obj in detected_objects:\n",
    "            measurement_history.append({\n",
    "                \"Time\": frame_count,  # 時刻（フレーム番号）\n",
    "                \"Range\": obj[0],      # 距離 [m]\n",
    "                \"Angle\": obj[1],      # 角度 [度]\n",
    "                \"X\": obj[2],          # X座標 [m]\n",
    "                \"Y\": obj[3]           # Y座標 [m]\n",
    "            })\n",
    "    else:\n",
    "        # 何も検出されなかった場合も、時刻だけ記録したい場合は以下のようにNaNを入れる\n",
    "        # (不要であればこのelseブロックは削除してください)\n",
    "        measurement_history.append({\n",
    "            \"Time\": frame_count,\n",
    "            \"Range\": np.nan,\n",
    "            \"Angle\": np.nan,\n",
    "            \"X\": np.nan,\n",
    "            \"Y\": np.nan\n",
    "        })\n",
    "    \n",
    "    cy_idx += cy_interval\n",
    "    ve_idx += ve_interval\n",
    "    frame_count += 1\n",
    "    \n",
    "# csvファイルに保存\n",
    "# --- 6. CSVへの保存 ---\n",
    "df_measurements = pd.DataFrame(measurement_history)\n",
    "\n",
    "# 保存\n",
    "csv_filename = \"measurements.csv\"\n",
    "df_measurements.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(\"\\nData generation complete.\")\n",
    "print(f\"Saved '{csv_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f10e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
